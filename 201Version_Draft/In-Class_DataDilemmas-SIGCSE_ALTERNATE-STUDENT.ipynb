{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nifty Assignment In-Class Alternate - Data Dilemmas: Ethics in an Algorithmic World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Put your name here</p>\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*rY3-IGAtdqiDDA9cutdOZA@2x.png\" width=600>\n",
    "\n",
    "## Learning Goals:\n",
    "\n",
    "By the end of this assignment, you should be able to:\n",
    "* Evaluate the impact the data and algorithmic bias can have on real-life decisions\n",
    "* Differentiate between intent and impact of Machine Learning models\n",
    "* Identify benefits and consequences of using ML and AI tools\n",
    "* Compare similarities between models and simulations to real-life inequities\n",
    "* Read and interpret professional code built to create a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survial of the Best Fit\n",
    "In the pre-class assignment, you played [\"Survival of the Best Fit\"](https://www.survivalofthebestfit.com/) and explored how bias inherent in our world and data can influence the results of an algorithm. Today, we are going to take a deeper dive in to the data that was used to create the simulation and explore how this game mimics hiring practices used by everyday companies. \n",
    "\n",
    "&#9989;&nbsp; In your groups, take a few minutes to discuss things you noticed about the game. Write down a few thoughts below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down some notes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Your Own Survival of the Best Fit\n",
    "In this portion of the assignment, you are tasked with recreating the main pieces of the simulation. We won't worry about all the fancy visualizations, but you will build the data and classification modeling for hiring in a similar manner to \"Survival of the Best Fit.\"\n",
    "\n",
    "We will guide you through the main portions of developing the code, but all of the code will be written by you and your group. At each stage, we encourage you to chat with your group and create a plan before coding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "To create the simulation, the creators of \"Survival of the Best Fit\" curated a data set of the blue and orange people and their associated skills. As you learned from playing the simulation, each group's skillset contained a specific amount of values representing the inherent biases that exist in our world. Remember, these are not meant to highlight that any one group is superior to the other, rather that issues of bias affect the opportunities that people have access to.\n",
    "\n",
    "&#9989;&nbsp; With your group talk about the differences between the blue and orange people and their associated skill sets. What skills were included? What values were typical for each group? At this stage, only include the predictor variables for employability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;&nbsp; Now, with your group, write pseudocode to plan how you will create the dataset in code, incorporating the differences you discussed above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## add your code here! Add more blocks as needed. Feel free to create a separate file if that is easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;&nbsp; Now, brainstorm a way to calculate the response value, 'employability'. This column of values should be 0 (not employable) or 1 (employable). Create a systematic way to assign these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## add your code here! Add more blocks as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Hiring\n",
    "At this point, you should have a dataset with blue or orange people containing their skillset values and employability value. Now, you will implement a classifier trained on the data you created that with predict whether an individual candidate will be employable based on their skill set. \n",
    "\n",
    "&#9989;&nbsp; With your group, decide on a classifier and implement it in code. \n",
    "\n",
    "Note, similar to the data creation stage, the results are not meant to indicate that one group is superior to the other. Your model should show how the bias embedded in the data and used to train the algorithm appears in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigate Harm\n",
    "Like Survival of the Best Fit, your model should indicate bias towards one of your groups. However, there are many ways that we can attempt to mitigate the harm a model like this would cause on hiring practices. Ideally, we want to hire a variety of candidates with a diverse set of experiences. \n",
    "\n",
    "&#9989;&nbsp; With your group, brainstorm ways in which an algorithm like this could be implemented in a way that minimizes the harm it causes. This could include changes to the code, changes to the implementation, other things to consider when hiring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Your Code\n",
    "Now open the `biased_data_gen.ipynb` file. This file contains the code that the authors of Survival of the Best Fit used to generate the data in their similuation. \n",
    "\n",
    "\n",
    "&#9989;&nbsp; Compare and contrast the approaches that were taken. What things did you account for? How did you account for it? Was it similar or different to the authors of Survival of the Best Fit?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflecting\n",
    "\n",
    "After you finish going through the biased data generation notebook, take a few minutes to reflect on the code and the data. Write down some thoughts below. How does the simulated data reflect real systemic issues present in our world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life Application\n",
    "It turns out Amazon (and [many more companies](https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination ) more recently) have been using Machine Learning and AI algorithm to assist in their hiring practices with mixed success. \n",
    "\n",
    "&#9989;&nbsp; Take a few minutes to read [\"Amazon ditched AI recruiting tool that favored men for technical jobs\"](https://theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine). \n",
    "\n",
    "### Discuss\n",
    "\n",
    "&#9989;&nbsp;  Discuss the follow questions with your group and take some notes on what you talk about. \n",
    "1.  What connections do you seen between \"Survival of the Best Fit\" and Amazon's real-life recruiting tool?\n",
    "2.  Why was Amazon's algorithm bias? What was biased about the training data? \n",
    "3.  How would you feel if you knew a company you applied to was using AI to judge candidates' applications? \n",
    "4.  If you were in a hiring role, would you feel comfortable using AI in hiring decisions? What steps might you take to help mitigate bias? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down some notes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share Your Highlights\n",
    "We will spend the last 10-15 minutes of class sharing what you learned and discussed. Make sure to note a few things to share with the rest of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways from Today's In-Class\n",
    "Today's assignment should have made you more aware about the power and the real-life harm that algorithm can cause. While they can provide great benefits like being cost-effective and speeding up time-consuming processes, they can also perpetuate harm existent in our world. Some more takeaways:\n",
    "- Pros: \n",
    "  * Algorithms can help reduce workload and synthesize large amounts of data. \n",
    "  * When implemented appropriately and thoughtfully, algorithms may help uncover patterns in candidates. \n",
    "- Cons: \n",
    "  * Algorithms reflect the data they are given. Bias in the data implies there is bias in the model. \n",
    "  * As we learned in Day 4, all data contains bias!\n",
    "  * Bias goes beyond gender, as we talked about in this case. It can also portray ageism, ableism, racism, socioeconomic status, etc. Similarly, algorithms can favor key words in resumes that might not be present in resumes of candidates that are highly qualified.\n",
    "  * Not using data that explicitly contains race, sex, or other identities does not mean that our algorithms will not negatively impact certain groups. These groups tend to be the most marginalized and underrepresented.\n",
    "\n",
    "Read More in [Algorithmic and Data Bias](https://medium.com/@sahin.samia/navigating-the-pitfalls-of-ai-in-hiring-unveiling-algorithmic-bias-9e62b50b3f65#:~:text=Imagine%20AI%20tools%20as%20mirrors,and%20diversity%20in%20the%20workplace.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Add any last reflections here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you're done!\n",
    "\n",
    "Submit this assignment by uploading your notebook to the course web page. \n",
    "\n",
    "See you next class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was designed by AUTHOR XX AND AUTHOR XX (2024). \n",
    "\n",
    "&#169; Copyright 2024, XX at XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
